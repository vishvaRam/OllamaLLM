{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\murth\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "info = \"generate minutes of meeting for this conversation:\"\n",
    "\n",
    "\n",
    "conv =\"\"\"\n",
    "Alice: Good morning, everyone. Thanks for making it to the meeting. We have a few key points to cover today. First, I’d like to get an update on the development progress. Bob, how are things going on your end?\n",
    "\n",
    "Bob: Good morning, Alice. The development is on track. We’ve just finished the beta version of the new feature, and it’s ready for initial testing. However, we’ve encountered a few minor bugs that need fixing, which might take an extra couple of days.\n",
    "\n",
    "Alice: That sounds promising. Do you anticipate any major roadblocks that could delay the launch?\n",
    "\n",
    "Bob: No major roadblocks, but we need to ensure thorough testing to catch any issues before the release. I’ve also allocated extra resources to expedite the debugging process.\n",
    "\n",
    "Alice: Great to hear. Carol, how are the marketing preparations coming along?\n",
    "\n",
    "Carol: Good morning, everyone. We’re gearing up for the product launch. The marketing campaign is in its final stages. We have the social media strategy ready, and the email campaigns are scheduled. I’m working closely with the design team to finalize the promotional materials.\n",
    "\n",
    "Alice: Excellent. Have you planned any special promotions or events for the launch?\n",
    "\n",
    "Carol: Yes, we’re planning a live demo event next week, and we’ve lined up a few influencers to help spread the word. Additionally, we’ll be running a limited-time discount for early adopters to generate buzz and encourage quick sign-ups.\n",
    "\n",
    "Alice: That sounds comprehensive. Bob, do you think the development team can support the demo event next week in case we run into any technical issues?\n",
    "\n",
    "Bob: Absolutely. I’ll make sure we have a couple of team members on standby during the event to handle any technical problems that might arise.\n",
    "\n",
    "Alice: Perfect. Lastly, let’s discuss the timeline. Assuming we fix the bugs and the testing goes smoothly, are we still on track for the launch date?\n",
    "\n",
    "Bob: Yes, if everything goes as planned, we should be able to launch on the scheduled date. We’re pushing hard to make sure there are no delays.\n",
    "\n",
    "Carol: From a marketing perspective, we’re all set to align with the launch date. Everything is synced up to go live as soon as we get the green light from the development team.\n",
    "\n",
    "Alice: Wonderful. Let’s aim to reconvene later this week for a final check-in before the launch. Thanks for the updates, everyone. Let’s keep up the good work.\n",
    "\n",
    "Bob: Sounds good. I’ll keep you posted on the progress.\n",
    "\n",
    "Carol: Thanks, Alice. Looking forward to a successful launch.\n",
    "\n",
    "Alice: Great. Meeting adjourned. Have a productive day, everyone!\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_id= \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,device_map=\"auto\", torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot who always responds in the style of a pirate. \n",
      "<|user|>\n",
      "How many helicopters can a human eat in one sitting? \n",
      "<|assistant|>\n",
      "A human can eat one helicopter in one sitting. A helicopter is a large, round aircraft with rotors that turn to move it forward. In comparison, a human has about 1,400 to 1,800 square inches of digestive tract, which is not much room to fit a whole helicopter. Therefore, a human can't eat as much as a helicopter, which is a large and complex structure.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the conversation\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a friendly chatbot who always responds in the style of a pirate.\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"How many helicopters can a human eat in one sitting?\"},\n",
    "]\n",
    "\n",
    "# Format the messages\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "# Tokenize the input\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "# Generate a response\n",
    "output = model.generate(input_ids, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "\n",
    "# Decode the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the response\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
